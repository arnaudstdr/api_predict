# ğŸ§  API Predict

Mini API FastAPI servant de base qui illustre comment transformer un modÃ¨le Python simple en service web conteneurisÃ©.

---

## ğŸš€ Fonctionnement

Le service expose deux endpoints :
- **GET /health** â†’ vÃ©rifie que lâ€™API est opÃ©rationnelle (`{"status": "ok"}`)
- **POST /predict** â†’ renvoie une prÃ©diction simple Ã  partir dâ€™un input `x` (`y = 2x + 1`)

---

## ğŸ§© ExÃ©cution en local

### 1. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 2. Lancer lâ€™API
```bash
uvicorn app.main:app --reload
```

### 3. Tester
- [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) â†’ interface Swagger  
- Exemple requÃªte :
```bash
curl -X POST http://127.0.0.1:8000/predict -H "Content-Type: application/json" -d '{"x": 3}'
```

RÃ©sultat attendu :
```json
{"prediction": 7}
```

---

## ğŸ³ ExÃ©cution avec Docker

### 1. Construire lâ€™image
```bash
docker build -t api_predict .
```

### 2. Lancer le conteneur
```bash
docker run -p 8000:8000 api_predict
```

### 3. VÃ©rifier le fonctionnement
```bash
curl http://127.0.0.1:8000/health
```

---

## ğŸ“¦ Structure du projet

```
api_predict/
â”œâ”€ app/
â”‚  â”œâ”€ __init__.py
â”‚  â””â”€ main.py
â”œâ”€ requirements.txt
â”œâ”€ Dockerfile
â””â”€ README.md
```

---

## QualitÃ© du code
Ce projet utilise :
- **Ruff** pour le linting (`ruff check .`)
- **Black** pour le formatage (`black .`)

## ğŸš€ CI/CD

Le projet utilise GitHub Actions pour :
- âœ… VÃ©rification de la qualitÃ© du code (Ruff + Black)
- âœ… ExÃ©cution des tests unitaires (pytest)
- âœ… Construction de l'image Docker (ARM64)

Le workflow se dÃ©clenche automatiquement sur chaque push et pull request.

---

## Tracking et monitoring avec MLflow

Le projet utilise **MLflow** pour suivre les paramÃ¨tres et rÃ©sultats de chaque prÃ©diction.  
Chaque requÃªte sur `/predict` crÃ©e un *run* MLflow, enregistrant :
- les paramÃ¨tres (`coef`, `bias`, `x`)
- les mÃ©triques (`output_y`)
- les horodatages dâ€™exÃ©cution

Pour visualiser les runs :
```bash
mlflow ui
```
**Puis ouvre http://127.0.0.1:5000**

---

## Interface Streamlit (Dashboad local)
Une interface Streamlit est disponible pour afficher les runs MLflow sans lancer l'UI par dÃ©faut :
```bash
streamlit run app/mlflow_ui.py
```
Elle affiche :
- la liste des expÃ©riences MLflow
- les paramÃ¨tres eet mÃ©triques loggÃ©s
- une visualisation dynamique des prÃ©dictions

---

## Prochaine Ã©tape

Mettre en place la dÃ©tection de **data drift** et la validation du modÃ¨le avec **Evidently** pour :
- comparer les distributions entre jeux de donnÃ©es dâ€™entraÃ®nement et de production
- gÃ©nÃ©rer un rapport HTML automatisÃ© dans `/reports/`
- suivre la dÃ©rive des donnÃ©es dans le temps